---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  collapse = FALSE,
  warning = FALSE,
  message = TRUE,
  tidy = FALSE,
  fig.align='center',
  comment = "#>",
  fig.path = "man/figures/README-",
  R.options = list(width = 200)
)

#FIXME NOT SURE WHY rvest IS NOT IMPORTING FROM NAMESPACE 
library(rvest)
```



# Scrape, parse, and analyze the Congressional Record 

<img src="man/figures/logo.png" width="150" />


### Installation
```
devtools::install_github("judgelord/congressionalrecord")
```

```{r, message=FALSE}
library(congressionalrecord)
```

This package depends on the `legislators` package to match legislators to their ICPSR/voteview id numbers.

```
devtools::install_github("judgelord/legislators")
```

```{r, message=FALSE}
library(legislators)
```

# Usage

This package contains functions to do three things: (1) scrape, (2) parse, and (3) analyze the Congressional Record

### 1. Scrape metadata from congress.gov and download the text of the Congressional Record

There are two main scraper functions to (1) scrape metadata on sections of the record (e.g. "house-section" or "sentate-section"), including URLs to the raw text for that section and then (2) save them as htm files in a directory.

`get_cr_df()` first scrapes metadata for all subsections for each day of the record, including headers and links to the raw text. 

```{r}
cr_metadata <- get_cr_df(as.Date("2007/03/01"), section = "senate-section")

cr_metadata
```

Scraper methods are described [here](https://judgelord.github.io/congressionalrecord/scraper.html) along with code for tables and figures to summarize theese metadata

```{r, echo= FALSE}
knitr::include_graphics("man/figures/cr_subtypes-1.png")
```

Crucial for second next step, these metadata include the URL to the full text. We could download it in PDF or HTML, but those formats take up more space than plain text without adding much value. (Indeed, PDFs are harder to work with.) 

Paste one of these URLs into your browser and click on "View TXT in new window" to see what we will be downloading: 

```{r}
# URL to raw text .htm
head(cr_metadata$url)
```

`get_cr_htm()` then downloads the raw text of each subsection as a .htm file. By default, `get_cr_htm()` downloads to a "data/htm" directory. In future versions, users will be able to provide a different location to the `directory` argument.  

```{r}
# download raw text .htm file
get_cr_htm(cr_metadata$url[1])

# this is what the raw text file "data/htm/CREC-2007-03-01-pt1-PgS2437.htm" looks like
readLines(here::here("data", "htm", "CREC-2007-03-01-pt1-PgS2437.htm")) 
```


### 2. Parse the record into .txt files by speaker

- The next set of functions to parse htm sections of the record by speaker and tag members with their ICPSR ID numbers. By default, `parse_cr()` will parse all htm files in the "data/htm" directory for dates that do not already appear in a "data/txt" directory. You may specify a custom vector of `dates` or `skip_parsed = FALSE` if you don't want to skipped files already parsed.
- the parser methods are explained [here](https://judgelord.github.io/congressionalrecord/speakers)

```{r}
# default location where txt files will be saved
directory <- here::here("data", "txt")

# parse congressional record htm files by speaker
parse_cr()

parsed_cr <- list.files(directory, recursive = T)

head(parsed_cr)
```

- the parsed .txt directory looks like this:

![](man/figures/winstat.png)

Speeches by John Conyers are in folder "10713" (his ICPSR number)

```{r}
readLines(here::here(directory, parsed_cr[1])) 

readLines(here::here(directory, parsed_cr[2])) 

readLines(here::here(directory, parsed_cr[3])) 

```

Speeches by Ted Kennedy are in folder "10808" (his ICPSR number)

```{r}
readLines(here::here(directory, parsed_cr[4])) 
```

- `count_speeches.R` contains additional methods to count speeches per member that will be included in future versions of `congressionalrecord`
- summary tables and figures of speech counts are [here](https://judgelord.github.io/cr/summary.html)

---

### 3. Count and extract sentences that contain user-specified phrases

- Preliminary work on feature extraction is [here](https://judgelord.github.io/cr/features)  
- There is also a brief tutorial on feature extraction at the end of the scraper vignette [here](https://judgelord.github.io/congressionalrecord/scraper.html#Text_features)

![](man/figures/covid-1.png)


### Notes about these data and methods

Notes about the parser

- The parser inserts ":::" after the speaker's name in the parsed text to make them easy to extract.
- Parsed speeches include where members introduce legislation into the record. These are actually read by the clerk (beginning with the string "The Clerk read the title of the bill."), but I decided to keep them associated with the member who introduced them. 
- The introduction of speakers to the floor appear as separate "speeches." Most all analyses will delete these and other super-short texts that are procedural things like "I yield back." Introductions in the parsed text look like this: "HON. JOHN D. DINGELL :::  of Michigan in the house of representatives"--notably these intros contain state names.
- Occasionally, when a speaker makes a long speech, GPO divides it into subsections that don't have the speaker's name on the page (either in html or pdf). (For example, [this speech](https://www.congress.gov/congressional-record/2020/12/17/senate-section/article/S7563-8) by Senator Durbin). These get parsed as "headers" but are much longer than the typical header and are thus easy to identify. In the next version of the parser or some post hoc correction, I hope to re-attach these to the earlier pages of the speech.


### Other notes 

Hein-bound data   

- Before deciding to scrape and parse the record from scratch, I tried to use existing speech data from Hein bound. Unfortunately, these data are incomplete and have a few errors. Most notably, they do not retain the date of the speech. My notes on these data and code to merge them with voteview data [here](https://judgelord.github.io/cr/member_data). A few plots comparing Hein-bound speech counts to NOMINATE scores and vote share are [here](https://judgelord.github.io/cr/speeches)

## To Do

- [x] Exclude prayer, the pledge, the journal, resignation, adjournment, executive communications, announcements, communications, appointment, reappointment, recess, recall, designations, additional sponsors, and other proceedural sections. (These texts are parsed and saved in the "NA" folder.)

- [x] Parse sections with more than one speaker, starting with "[SPEAKER NAME]. (Mister|Madam) Speaker, ". For example, see the Impeachment speaches, where speakers yield time to other speakers.

- [ ] Check members with irregular capitalization beyond "Mc|Mac|Des|De|La"

- [x] Match speaker names to ICPSR IDs like I did [here](https://judgelord.github.io/cr/speeches) for the hein-bound data using the crosswalk crated [here](https://judgelord.github.io/cr/member_data.html).

- [ ] File bug report for names to fix in `legislators` package: Susan *W.* Brrooks

